{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "143e3761",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.estimator import Framework\n",
    "\n",
    "ecr_namespace = 'sagemaker-training-containers/'\n",
    "prefix = 'framework-container'\n",
    "\n",
    "ecr_repository_name = ecr_namespace + prefix\n",
    "role = get_execution_role()\n",
    "account_id = role.split(':')[4]\n",
    "region = boto3.Session().region_name\n",
    "sagemaker_session = sagemaker.session.Session()\n",
    "bucket = sagemaker_session.default_bucket()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "37566643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping docker: \u001b[60G[\u001b[0;32m  OK  \u001b[0;39m]\n",
      "Starting docker:\t.\u001b[60G[\u001b[0;32m  OK  \u001b[0;39m]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "docker_mages_directory = \"/home/ec2-user/SageMaker/docker\"\n",
    "docker_settings_file = \"/etc/docker/daemon.json\"\n",
    "\n",
    "!sudo chmod 777  /etc/docker/daemon.json\n",
    "\n",
    "if not os.path.exists(docker_mages_directory):\n",
    "    os.mkdir(docker_mages_directory)\n",
    "with open(docker_settings_file, \"r\") as f:\n",
    "    docker_settings = json.loads(f.read())\n",
    "\n",
    "docker_settings[\"data-root\"] = docker_mages_directory\n",
    "\n",
    "with open(docker_settings_file, \"w\") as f:\n",
    "    f.write(json.dumps(docker_settings))\n",
    "    \n",
    "!sudo service docker restart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f8eaab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3ae66d6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "Login Succeeded\n",
      "Sending build context to Docker daemon  40.45MB\n",
      "Step 1/13 : ARG CUDA_VER=11.0\n",
      "Step 2/13 : ARG LINUX_VER=ubuntu18.04\n",
      "Step 3/13 : ARG PYTHON_VER=3.7\n",
      "Step 4/13 : ARG RAPIDS_VER=0.19\n",
      "Step 5/13 : ARG FROM_IMAGE=rapidsai/rapidsai-core\n",
      "Step 6/13 : FROM ${FROM_IMAGE}:${RAPIDS_VER}-cuda${CUDA_VER}-runtime-${LINUX_VER}-py${PYTHON_VER}\n",
      " ---> 5919023f2ac9\n",
      "Step 7/13 : ARG CUDA_VER\n",
      " ---> Using cache\n",
      " ---> d3db16ca4e8b\n",
      "Step 8/13 : ENV PYTHONDONTWRITEBYTECODE=1     PYTHONUNBUFFERED=1     PYTHONIOENCODING=UTF-8     LANG=C.UTF-8     LC_ALL=C.UTF-8     SAGEMAKER_TRAINING_MODULE=sagemaker_mxnet_container.training:main     LD_LIBRARY_PATH=/opt/conda/envs/rapids/lib:/usr/local/lib:$LD_LIBRARY_PATH     PATH=/opt/conda/envs/rapids/bin:/usr/local/bin:$PATH\n",
      " ---> Using cache\n",
      " ---> 8356e87a28f3\n",
      "Step 9/13 : RUN apt-get update     && apt-get install -y --no-install-recommends     build-essential\n",
      " ---> Using cache\n",
      " ---> 70f765b30da2\n",
      "Step 10/13 : RUN source activate rapids     && pip install numpy==1.19.5\n",
      " ---> Running in 70a154987b8f\n",
      "\u001b[91mWARNING: Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
      "distutils: /opt/conda/envs/rapids/include/python3.7m/UNKNOWN\n",
      "sysconfig: /opt/conda/envs/rapids/include/python3.7m\n",
      "\u001b[0m\u001b[91mWARNING: Additional context:\n",
      "user = False\n",
      "home = None\n",
      "root = None\n",
      "prefix = None\n",
      "\u001b[0mCollecting numpy==1.19.5\n",
      "  Downloading numpy-1.19.5-cp37-cp37m-manylinux2010_x86_64.whl (14.8 MB)\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.20.2\n",
      "    Uninstalling numpy-1.20.2:\n",
      "      Successfully uninstalled numpy-1.20.2\n",
      "\u001b[91mWARNING: Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
      "distutils: /opt/conda/envs/rapids/include/python3.7m/UNKNOWN\n",
      "sysconfig: /opt/conda/envs/rapids/include/python3.7m\n",
      "\u001b[0m\u001b[91mWARNING: Additional context:\n",
      "user = False\n",
      "home = None\n",
      "root = None\n",
      "prefix = None\n",
      "\u001b[0m\u001b[91mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "dask-cudf 0.19.2 requires cupy-cuda102, which is not installed.\n",
      "cudf 0.19.2 requires cupy-cuda110, which is not installed.\n",
      "\u001b[0mSuccessfully installed numpy-1.19.5\n",
      "\u001b[91mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\n",
      "\u001b[0mRemoving intermediate container 70a154987b8f\n",
      " ---> b3b6e265abe0\n",
      "Step 11/13 : RUN source activate rapids     && pip install --no-cache -U --no-use-pep517 mxnet-cu$(echo ${CUDA_VER} | sed 's/\\.//')     setuptools     wheel     autogluon==0.2.0     sagemaker-mxnet-training\n",
      " ---> Running in f89436f20959\n",
      "\u001b[91mWARNING: Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
      "distutils: /opt/conda/envs/rapids/include/python3.7m/UNKNOWN\n",
      "sysconfig: /opt/conda/envs/rapids/include/python3.7m\n",
      "\u001b[0m\u001b[91mWARNING: Additional context:\n",
      "user = False\n",
      "home = None\n",
      "root = None\n",
      "prefix = None\n",
      "\u001b[0mCollecting mxnet-cu110\n",
      "  Downloading mxnet_cu110-1.8.0.post0-py2.py3-none-manylinux2014_x86_64.whl (323.5 MB)\n",
      "Requirement already satisfied: setuptools in /opt/conda/envs/rapids/lib/python3.7/site-packages (49.6.0.post20210108)\n",
      "Collecting setuptools\n",
      "  Downloading setuptools-56.1.0-py3-none-any.whl (785 kB)\n",
      "Requirement already satisfied: wheel in /opt/conda/envs/rapids/lib/python3.7/site-packages (0.36.2)\n",
      "Collecting autogluon==0.2.0\n",
      "  Downloading autogluon-0.2.0-py3-none-any.whl (5.4 kB)\n",
      "Collecting sagemaker-mxnet-training\n",
      "  Downloading sagemaker_mxnet_training-4.3.0.tar.gz (8.8 kB)\n",
      "Collecting autogluon.features==0.2.0\n",
      "  Downloading autogluon.features-0.2.0-py3-none-any.whl (48 kB)\n",
      "Collecting autogluon.core==0.2.0\n",
      "  Downloading autogluon.core-0.2.0-py3-none-any.whl (334 kB)\n",
      "Collecting autogluon.tabular[all]==0.2.0\n",
      "  Downloading autogluon.tabular-0.2.0-py3-none-any.whl (250 kB)\n",
      "Collecting autogluon.vision==0.2.0\n",
      "  Downloading autogluon.vision-0.2.0-py3-none-any.whl (31 kB)\n",
      "Collecting autogluon.mxnet==0.2.0\n",
      "  Downloading autogluon.mxnet-0.2.0-py3-none-any.whl (28 kB)\n",
      "Collecting autogluon.text==0.2.0\n",
      "  Downloading autogluon.text-0.2.0-py3-none-any.whl (48 kB)\n",
      "Collecting autogluon.extra==0.2.0\n",
      "  Downloading autogluon.extra-0.2.0-py3-none-any.whl (24 kB)\n",
      "Collecting boto3\n",
      "  Downloading boto3-1.17.66.tar.gz (98 kB)\n",
      "Requirement already satisfied: pandas<2.0,>=1.0.0 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from autogluon.core==0.2.0->autogluon==0.2.0) (1.2.4)\n",
      "Requirement already satisfied: cython in /opt/conda/envs/rapids/lib/python3.7/site-packages (from autogluon.core==0.2.0->autogluon==0.2.0) (0.29.23)\n",
      "Collecting graphviz<0.9.0,>=0.8.1\n",
      "  Downloading graphviz-0.8.4-py2.py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: tornado>=5.0.1 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from autogluon.core==0.2.0->autogluon==0.2.0) (6.1)\n",
      "Requirement already satisfied: dask>=2.6.0 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from autogluon.core==0.2.0->autogluon==0.2.0) (2021.4.0)\n",
      "Collecting autograd>=1.3\n",
      "  Downloading autograd-1.3.tar.gz (38 kB)\n",
      "Collecting dill==0.3.3\n",
      "  Downloading dill-0.3.3-py2.py3-none-any.whl (81 kB)\n",
      "Requirement already satisfied: distributed>=2.6.0 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from autogluon.core==0.2.0->autogluon==0.2.0) (2021.4.0)\n",
      "Collecting ConfigSpace==0.4.18\n",
      "  Downloading ConfigSpace-0.4.18.tar.gz (950 kB)\n",
      "Requirement already satisfied: scipy<1.7,>=1.5.4 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from autogluon.core==0.2.0->autogluon==0.2.0) (1.6.0)\n",
      "Requirement already satisfied: numpy==1.19.5 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from autogluon.core==0.2.0->autogluon==0.2.0) (1.19.5)\n",
      "Collecting paramiko>=2.4\n",
      "  Downloading paramiko-2.7.2-py2.py3-none-any.whl (206 kB)\n",
      "Requirement already satisfied: requests in /opt/conda/envs/rapids/lib/python3.7/site-packages (from autogluon.core==0.2.0->autogluon==0.2.0) (2.25.1)\n",
      "Collecting scikit-learn<0.25,>=0.23.2\n",
      "  Downloading scikit_learn-0.24.2-cp37-cp37m-manylinux2010_x86_64.whl (22.3 MB)\n",
      "Requirement already satisfied: tqdm>=4.38.0 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from autogluon.core==0.2.0->autogluon==0.2.0) (4.60.0)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/envs/rapids/lib/python3.7/site-packages (from autogluon.core==0.2.0->autogluon==0.2.0) (3.4.1)\n",
      "Collecting gluoncv<0.11,>=0.10.1.post0\n",
      "  Downloading gluoncv-0.10.1.post0-py3-none-any.whl (1.1 MB)\n",
      "Requirement already satisfied: pytest in /opt/conda/envs/rapids/lib/python3.7/site-packages (from autogluon.extra==0.2.0->autogluon==0.2.0) (6.2.3)\n",
      "Collecting openml\n",
      "  Downloading openml-0.12.1.tar.gz (115 kB)\n",
      "Collecting Pillow<=8.1\n",
      "  Downloading Pillow-8.1.0-cp37-cp37m-manylinux1_x86_64.whl (2.2 MB)\n",
      "Requirement already satisfied: psutil<5.9,>=5.7.3 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from autogluon.tabular[all]==0.2.0->autogluon==0.2.0) (5.8.0)\n",
      "Requirement already satisfied: networkx<3.0,>=2.3 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from autogluon.tabular[all]==0.2.0->autogluon==0.2.0) (2.5.1)\n",
      "Collecting fastai<3.0,>=2.0\n",
      "  Downloading fastai-2.3.1-py3-none-any.whl (194 kB)\n",
      "Collecting xgboost<1.4,>=1.3.2\n",
      "  Downloading xgboost-1.3.3-py3-none-manylinux2010_x86_64.whl (157.5 MB)\n",
      "Collecting catboost<0.26,>=0.24.0\n",
      "  Downloading catboost-0.25.1-cp37-none-manylinux1_x86_64.whl (67.3 MB)\n",
      "Collecting lightgbm<4.0,>=3.0\n",
      "  Downloading lightgbm-3.2.1-py3-none-manylinux1_x86_64.whl (2.0 MB)\n",
      "Collecting torch<2.0,>=1.0\n",
      "  Downloading torch-1.8.1-cp37-cp37m-manylinux1_x86_64.whl (804.1 MB)\n",
      "Requirement already satisfied: pyarrow in /opt/conda/envs/rapids/lib/python3.7/site-packages (from autogluon.text==0.2.0->autogluon==0.2.0) (1.0.1)\n",
      "Collecting autogluon-contrib-nlp==0.0.1b20210201\n",
      "  Downloading autogluon_contrib_nlp-0.0.1b20210201-py3-none-any.whl (157 kB)\n",
      "Collecting sentencepiece==0.1.95\n",
      "  Downloading sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2 MB)\n",
      "Collecting yacs>=0.1.6\n",
      "  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
      "Collecting sacrebleu\n",
      "  Downloading sacrebleu-1.5.1-py3-none-any.whl (54 kB)\n",
      "Collecting tokenizers==0.9.4\n",
      "  Downloading tokenizers-0.9.4-cp37-cp37m-manylinux2010_x86_64.whl (2.9 MB)\n",
      "Collecting sacremoses>=0.0.38\n",
      "  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\n",
      "Requirement already satisfied: protobuf in /opt/conda/envs/rapids/lib/python3.7/site-packages (from autogluon-contrib-nlp==0.0.1b20210201->autogluon.text==0.2.0->autogluon==0.2.0) (3.15.8)\n",
      "Collecting contextvars\n",
      "  Downloading contextvars-2.4.tar.gz (9.6 kB)\n",
      "Collecting regex\n",
      "  Downloading regex-2021.4.4-cp37-cp37m-manylinux2014_x86_64.whl (720 kB)\n",
      "Collecting flake8\n",
      "  Downloading flake8-3.9.1-py2.py3-none-any.whl (73 kB)\n",
      "Collecting d8<1.0,>=0.0.2\n",
      "  Downloading d8-0.0.2.post0-py3-none-any.whl (28 kB)\n",
      "Requirement already satisfied: pyparsing in /opt/conda/envs/rapids/lib/python3.7/site-packages (from ConfigSpace==0.4.18->autogluon.core==0.2.0->autogluon==0.2.0) (2.4.7)\n",
      "Collecting future>=0.15.2\n",
      "  Downloading future-0.18.2.tar.gz (829 kB)\n",
      "Collecting plotly\n",
      "  Downloading plotly-4.14.3-py2.py3-none-any.whl (13.2 MB)\n",
      "Requirement already satisfied: six in /opt/conda/envs/rapids/lib/python3.7/site-packages (from catboost<0.26,>=0.24.0->autogluon.tabular[all]==0.2.0->autogluon==0.2.0) (1.15.0)\n",
      "Collecting kaggle\n",
      "  Downloading kaggle-1.5.12.tar.gz (58 kB)\n",
      "Collecting xxhash\n",
      "  Downloading xxhash-2.0.2-cp37-cp37m-manylinux2010_x86_64.whl (243 kB)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/envs/rapids/lib/python3.7/site-packages (from dask>=2.6.0->autogluon.core==0.2.0->autogluon==0.2.0) (5.4.1)\n",
      "Requirement already satisfied: toolz>=0.8.2 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from dask>=2.6.0->autogluon.core==0.2.0->autogluon==0.2.0) (0.11.1)\n",
      "Requirement already satisfied: partd>=0.3.10 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from dask>=2.6.0->autogluon.core==0.2.0->autogluon==0.2.0) (1.2.0)\n",
      "Requirement already satisfied: fsspec>=0.6.0 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from dask>=2.6.0->autogluon.core==0.2.0->autogluon==0.2.0) (2021.4.0)\n",
      "Requirement already satisfied: cloudpickle>=1.1.1 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from dask>=2.6.0->autogluon.core==0.2.0->autogluon==0.2.0) (1.6.0)\n",
      "Requirement already satisfied: tblib>=1.6.0 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from distributed>=2.6.0->autogluon.core==0.2.0->autogluon==0.2.0) (1.7.0)\n",
      "Requirement already satisfied: sortedcontainers!=2.0.0,!=2.0.1 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from distributed>=2.6.0->autogluon.core==0.2.0->autogluon==0.2.0) (2.3.0)\n",
      "Requirement already satisfied: click>=6.6 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from distributed>=2.6.0->autogluon.core==0.2.0->autogluon==0.2.0) (7.1.2)\n",
      "Requirement already satisfied: msgpack>=0.6.0 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from distributed>=2.6.0->autogluon.core==0.2.0->autogluon==0.2.0) (1.0.2)\n",
      "Requirement already satisfied: zict>=0.1.3 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from distributed>=2.6.0->autogluon.core==0.2.0->autogluon==0.2.0) (2.0.0)\n",
      "Collecting fastprogress>=0.2.4\n",
      "  Downloading fastprogress-1.0.0-py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: packaging in /opt/conda/envs/rapids/lib/python3.7/site-packages (from fastai<3.0,>=2.0->autogluon.tabular[all]==0.2.0->autogluon==0.2.0) (20.9)\n",
      "Collecting fastcore<1.4,>=1.3.8\n",
      "  Downloading fastcore-1.3.20-py3-none-any.whl (53 kB)\n",
      "Collecting torchvision>=0.8.2\n",
      "  Downloading torchvision-0.9.1-cp37-cp37m-manylinux1_x86_64.whl (17.4 MB)\n",
      "Collecting spacy<4\n",
      "  Downloading spacy-3.0.6-cp37-cp37m-manylinux2014_x86_64.whl (12.8 MB)\n",
      "Requirement already satisfied: pip in /opt/conda/envs/rapids/lib/python3.7/site-packages (from fastai<3.0,>=2.0->autogluon.tabular[all]==0.2.0->autogluon==0.2.0) (21.1)\n",
      "Collecting tensorboardx\n",
      "  Downloading tensorboardX-2.2-py2.py3-none-any.whl (120 kB)\n",
      "Collecting autocfg\n",
      "  Downloading autocfg-0.0.8-py3-none-any.whl (13 kB)\n",
      "Collecting portalocker\n",
      "  Downloading portalocker-2.3.0-py2.py3-none-any.whl (15 kB)\n",
      "Collecting decord\n",
      "  Downloading decord-0.5.2-py3-none-manylinux2010_x86_64.whl (14.1 MB)\n",
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.5.1.48-cp37-cp37m-manylinux2014_x86_64.whl (50.4 MB)\n",
      "Requirement already satisfied: decorator<5,>=4.3 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from networkx<3.0,>=2.3->autogluon.tabular[all]==0.2.0->autogluon==0.2.0) (4.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from pandas<2.0,>=1.0.0->autogluon.core==0.2.0->autogluon==0.2.0) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from pandas<2.0,>=1.0.0->autogluon.core==0.2.0->autogluon==0.2.0) (2021.1)\n",
      "Collecting bcrypt>=3.1.3\n",
      "  Downloading bcrypt-3.2.0-cp36-abi3-manylinux2010_x86_64.whl (63 kB)\n",
      "Collecting pynacl>=1.0.1\n",
      "  Downloading PyNaCl-1.4.0-cp35-abi3-manylinux1_x86_64.whl (961 kB)\n",
      "Requirement already satisfied: cryptography>=2.5 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from paramiko>=2.4->autogluon.core==0.2.0->autogluon==0.2.0) (3.4.7)\n",
      "Requirement already satisfied: cffi>=1.1 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from bcrypt>=3.1.3->paramiko>=2.4->autogluon.core==0.2.0->autogluon==0.2.0) (1.14.5)\n",
      "Requirement already satisfied: pycparser in /opt/conda/envs/rapids/lib/python3.7/site-packages (from cffi>=1.1->bcrypt>=3.1.3->paramiko>=2.4->autogluon.core==0.2.0->autogluon==0.2.0) (2.20)\n",
      "Requirement already satisfied: locket in /opt/conda/envs/rapids/lib/python3.7/site-packages (from partd>=0.3.10->dask>=2.6.0->autogluon.core==0.2.0->autogluon==0.2.0) (0.2.0)\n",
      "Requirement already satisfied: joblib in /opt/conda/envs/rapids/lib/python3.7/site-packages (from sacremoses>=0.0.38->autogluon-contrib-nlp==0.0.1b20210201->autogluon.text==0.2.0->autogluon==0.2.0) (1.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from scikit-learn<0.25,>=0.23.2->autogluon.core==0.2.0->autogluon==0.2.0) (2.1.0)\n",
      "Collecting blis<0.8.0,>=0.4.0\n",
      "  Downloading blis-0.7.4-cp37-cp37m-manylinux2014_x86_64.whl (9.8 MB)\n",
      "Collecting catalogue<2.1.0,>=2.0.3\n",
      "  Downloading catalogue-2.0.4-py3-none-any.whl (16 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2\n",
      "  Downloading preshed-3.0.5-cp37-cp37m-manylinux2014_x86_64.whl (126 kB)\n",
      "Collecting typer<0.4.0,>=0.3.0\n",
      "  Downloading typer-0.3.2-py3-none-any.whl (21 kB)\n",
      "Collecting pathy>=0.3.5\n",
      "  Downloading pathy-0.5.2-py3-none-any.whl (42 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.1\n",
      "  Downloading srsly-2.4.1-cp37-cp37m-manylinux2014_x86_64.whl (456 kB)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from spacy<4->fastai<3.0,>=2.0->autogluon.tabular[all]==0.2.0->autogluon==0.2.0) (2.11.3)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0\n",
      "  Downloading murmurhash-1.0.5-cp37-cp37m-manylinux2014_x86_64.whl (20 kB)\n",
      "Collecting wasabi<1.1.0,>=0.8.1\n",
      "  Downloading wasabi-0.8.2-py3-none-any.whl (23 kB)\n",
      "Collecting thinc<8.1.0,>=8.0.3\n",
      "  Downloading thinc-8.0.3-cp37-cp37m-manylinux2014_x86_64.whl (1.1 MB)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.4\n",
      "  Downloading spacy_legacy-3.0.5-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from spacy<4->fastai<3.0,>=2.0->autogluon.tabular[all]==0.2.0->autogluon==0.2.0) (3.7.4.3)\n",
      "Collecting cymem<2.1.0,>=2.0.2\n",
      "  Downloading cymem-2.0.5-cp37-cp37m-manylinux2014_x86_64.whl (35 kB)\n",
      "Collecting pydantic<1.8.0,>=1.7.1\n",
      "  Downloading pydantic-1.7.3-cp37-cp37m-manylinux2014_x86_64.whl (9.1 MB)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from catalogue<2.1.0,>=2.0.3->spacy<4->fastai<3.0,>=2.0->autogluon.tabular[all]==0.2.0->autogluon==0.2.0) (3.4.1)\n",
      "Collecting smart-open<4.0.0,>=2.2.0\n",
      "  Downloading smart_open-3.0.0.tar.gz (113 kB)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from requests->autogluon.core==0.2.0->autogluon==0.2.0) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from requests->autogluon.core==0.2.0->autogluon==0.2.0) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from requests->autogluon.core==0.2.0->autogluon==0.2.0) (1.26.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from requests->autogluon.core==0.2.0->autogluon==0.2.0) (2020.12.5)\n",
      "Requirement already satisfied: heapdict in /opt/conda/envs/rapids/lib/python3.7/site-packages (from zict>=0.1.3->distributed>=2.6.0->autogluon.core==0.2.0->autogluon==0.2.0) (1.0.1)\n",
      "Collecting sagemaker-training>=3.5.2\n",
      "  Downloading sagemaker_training-3.9.2.tar.gz (47 kB)\n",
      "Collecting retrying==1.3.3\n",
      "  Downloading retrying-1.3.3.tar.gz (10 kB)\n",
      "Collecting gevent\n",
      "  Downloading gevent-21.1.2-cp37-cp37m-manylinux2010_x86_64.whl (5.6 MB)\n",
      "Collecting inotify_simple==1.2.1\n",
      "  Downloading inotify_simple-1.2.1.tar.gz (7.9 kB)\n",
      "Collecting werkzeug>=0.15.5\n",
      "  Downloading Werkzeug-1.0.1-py2.py3-none-any.whl (298 kB)\n",
      "Collecting botocore<1.21.0,>=1.20.66\n",
      "  Downloading botocore-1.20.66-py2.py3-none-any.whl (7.5 MB)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from boto3->autogluon.core==0.2.0->autogluon==0.2.0) (0.10.0)\n",
      "Collecting s3transfer<0.5.0,>=0.4.0\n",
      "  Downloading s3transfer-0.4.2-py2.py3-none-any.whl (79 kB)\n",
      "Collecting immutables>=0.9\n",
      "  Downloading immutables-0.15-cp37-cp37m-manylinux1_x86_64.whl (101 kB)\n",
      "Collecting pycodestyle<2.8.0,>=2.7.0\n",
      "  Downloading pycodestyle-2.7.0-py2.py3-none-any.whl (41 kB)\n",
      "Collecting mccabe<0.7.0,>=0.6.0\n",
      "  Downloading mccabe-0.6.1-py2.py3-none-any.whl (8.6 kB)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/envs/rapids/lib/python3.7/site-packages (from flake8->autogluon-contrib-nlp==0.0.1b20210201->autogluon.text==0.2.0->autogluon==0.2.0) (4.0.1)\n",
      "Collecting pyflakes<2.4.0,>=2.3.0\n",
      "  Downloading pyflakes-2.3.1-py2.py3-none-any.whl (68 kB)\n",
      "Collecting greenlet<2.0,>=0.4.17\n",
      "  Downloading greenlet-1.0.0-cp37-cp37m-manylinux2010_x86_64.whl (160 kB)\n",
      "Collecting zope.event\n",
      "  Downloading zope.event-4.5.0-py2.py3-none-any.whl (6.8 kB)\n",
      "Collecting zope.interface\n",
      "  Downloading zope.interface-5.4.0-cp37-cp37m-manylinux2010_x86_64.whl (251 kB)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from jinja2->spacy<4->fastai<3.0,>=2.0->autogluon.tabular[all]==0.2.0->autogluon==0.2.0) (1.1.1)\n",
      "Collecting python-slugify\n",
      "  Downloading python_slugify-5.0.0-py2.py3-none-any.whl (6.8 kB)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from matplotlib->autogluon.core==0.2.0->autogluon==0.2.0) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from matplotlib->autogluon.core==0.2.0->autogluon==0.2.0) (1.3.1)\n",
      "Collecting liac-arff>=2.4.0\n",
      "  Downloading liac-arff-2.5.0.tar.gz (13 kB)\n",
      "Collecting xmltodict\n",
      "  Downloading xmltodict-0.12.0-py2.py3-none-any.whl (9.2 kB)\n",
      "Collecting minio\n",
      "  Downloading minio-7.0.3-py3-none-any.whl (75 kB)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from pytest->autogluon.extra==0.2.0->autogluon==0.2.0) (20.3.0)\n",
      "Requirement already satisfied: iniconfig in /opt/conda/envs/rapids/lib/python3.7/site-packages (from pytest->autogluon.extra==0.2.0->autogluon==0.2.0) (1.1.1)\n",
      "Requirement already satisfied: pluggy<1.0.0a1,>=0.12 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from pytest->autogluon.extra==0.2.0->autogluon==0.2.0) (0.13.1)\n",
      "Requirement already satisfied: py>=1.8.2 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from pytest->autogluon.extra==0.2.0->autogluon==0.2.0) (1.10.0)\n",
      "Requirement already satisfied: toml in /opt/conda/envs/rapids/lib/python3.7/site-packages (from pytest->autogluon.extra==0.2.0->autogluon==0.2.0) (0.10.2)\n",
      "Collecting text-unidecode>=1.3\n",
      "  Downloading text_unidecode-1.3-py2.py3-none-any.whl (78 kB)\n",
      "Collecting portalocker\n",
      "  Downloading portalocker-2.0.0-py2.py3-none-any.whl (11 kB)\n",
      "Building wheels for collected packages: ConfigSpace, autograd, future, smart-open, sagemaker-mxnet-training, retrying, sagemaker-training, inotify-simple, boto3, contextvars, kaggle, openml, liac-arff\n",
      "  Building wheel for ConfigSpace (setup.py): started\n",
      "  Building wheel for ConfigSpace (setup.py): finished with status 'done'\n",
      "  Created wheel for ConfigSpace: filename=ConfigSpace-0.4.18-cp37-cp37m-linux_x86_64.whl size=2902537 sha256=9d4f9db2a44c859e7b2f63552a3eb47fb3885902f9c68a7df0e6fa1dbef26493\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-_c3vcq_s/wheels/36/f7/0f/36f368c419ea1a8024fc3d6c078c3111dfef43fa1d14cfebe0\n",
      "  Building wheel for autograd (setup.py): started\n",
      "  Building wheel for autograd (setup.py): finished with status 'done'\n",
      "  Created wheel for autograd: filename=autograd-1.3-py3-none-any.whl size=47989 sha256=3b97852f2268c70ab7a4f725040b5e74f454aa48dd3626a0fc4ea2ac5cb4e569\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-_c3vcq_s/wheels/ef/32/31/0e87227cd0ca1d99ad51fbe4b54c6fa02afccf7e483d045e04\n",
      "  Building wheel for future (setup.py): started\n",
      "  Building wheel for future (setup.py): finished with status 'done'\n",
      "  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491059 sha256=c162c061b2239952542cc504832366f6ca7ea0806b23a74130dfeb748858b544\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-_c3vcq_s/wheels/56/b0/fe/4410d17b32f1f0c3cf54cdfb2bc04d7b4b8f4ae377e2229ba0\n",
      "  Building wheel for smart-open (setup.py): started\n",
      "  Building wheel for smart-open (setup.py): finished with status 'done'\n",
      "  Created wheel for smart-open: filename=smart_open-3.0.0-py3-none-any.whl size=107097 sha256=cfcfa3100b6683d138e6fdc17ece6a9ceeb587d2a3564558853f311a761474bf\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-_c3vcq_s/wheels/83/a6/12/bf3c1a667bde4251be5b7a3368b2d604c9af2105b5c1cb1870\n",
      "  Building wheel for sagemaker-mxnet-training (setup.py): started\n",
      "  Building wheel for sagemaker-mxnet-training (setup.py): finished with status 'done'\n",
      "  Created wheel for sagemaker-mxnet-training: filename=sagemaker_mxnet_training-4.3.0-py3-none-any.whl size=10130 sha256=fdf1cc33beb0c52f675d9aead18818a0532a1599f07fe08c19c2a5e3433b1707\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-_c3vcq_s/wheels/fa/36/c0/6691936342f248828cead7ae4a9af5fa44f3bb4f18f3dd2c8f\n",
      "  Building wheel for retrying (setup.py): started\n",
      "  Building wheel for retrying (setup.py): finished with status 'done'\n",
      "  Created wheel for retrying: filename=retrying-1.3.3-py3-none-any.whl size=11429 sha256=72f807caa20205ea37cc25bfb39743b2c9936bc79f4a9670fa73e3dde09b1a6a\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-_c3vcq_s/wheels/f9/8d/8d/f6af3f7f9eea3553bc2fe6d53e4b287dad18b06a861ac56ddf\n",
      "  Building wheel for sagemaker-training (setup.py): started\n",
      "  Building wheel for sagemaker-training (setup.py): finished with status 'done'\n",
      "  Created wheel for sagemaker-training: filename=sagemaker_training-3.9.2-cp37-cp37m-linux_x86_64.whl size=74593 sha256=52f27d118d4b8dd34c3a239c58424451b9e5235af6e1274a07c22344fc301897\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-_c3vcq_s/wheels/61/84/d3/e27b20dc06843ad7c3fb6ff67188d63b3776100582f3eba4c2\n",
      "  Building wheel for inotify-simple (setup.py): started\n",
      "  Building wheel for inotify-simple (setup.py): finished with status 'done'\n",
      "  Created wheel for inotify-simple: filename=inotify_simple-1.2.1-py3-none-any.whl size=8204 sha256=1c8741abdaeac2aa5f1f97af2f069d942672bbd331f6627789b4a5d285d75772\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-_c3vcq_s/wheels/ef/7e/4a/bfeb3216a60ab5e077958f5a1e980cc3de9663155cfb31c660\n",
      "  Building wheel for boto3 (setup.py): started\n",
      "  Building wheel for boto3 (setup.py): finished with status 'done'\n",
      "  Created wheel for boto3: filename=boto3-1.17.66-py2.py3-none-any.whl size=128923 sha256=2906a5038788d78e6e4809127f2eb407580811d1b405a7774ae378035c68ccac\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-_c3vcq_s/wheels/05/31/1d/5df0bfe1de7f5d46fdaf519830abfb491b7f52f76e1de003e0\n",
      "  Building wheel for contextvars (setup.py): started\n",
      "  Building wheel for contextvars (setup.py): finished with status 'done'\n",
      "  Created wheel for contextvars: filename=contextvars-2.4-py3-none-any.whl size=7665 sha256=6bf6968616c8145ebe5d65534d8d46fd15dcf8a69eb7cabd4cfc1915c9793c7b\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-_c3vcq_s/wheels/0a/11/79/e70e668095c0bb1f94718af672ef2d35ee7a023fee56ef54d9\n",
      "  Building wheel for kaggle (setup.py): started\n",
      "  Building wheel for kaggle (setup.py): finished with status 'done'\n",
      "  Created wheel for kaggle: filename=kaggle-1.5.12-py3-none-any.whl size=73053 sha256=1f793fb0c9d87d10acd61190b5e56a1551c21b23e5aa2f4c8cabe403ea007266\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-_c3vcq_s/wheels/62/d6/58/5853130f941e75b2177d281eb7e44b4a98ed46dd155f556dc5\n",
      "  Building wheel for openml (setup.py): started\n",
      "  Building wheel for openml (setup.py): finished with status 'done'\n",
      "  Created wheel for openml: filename=openml-0.12.1-py3-none-any.whl size=132143 sha256=b411142720565f174352ea63cb60bca9ccce7dc22fff229253cdadd5500431c7\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-_c3vcq_s/wheels/ea/77/16/c4f01efd89dd4a30524ec3bb91ba344b2c890031c0a85653b2\n",
      "  Building wheel for liac-arff (setup.py): started\n",
      "  Building wheel for liac-arff (setup.py): finished with status 'done'\n",
      "  Created wheel for liac-arff: filename=liac_arff-2.5.0-py3-none-any.whl size=11731 sha256=0d98f1bcbc9945b8599948d72fd15a7e3792397085d6173ee9c5d42a924b04d8\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-_c3vcq_s/wheels/1f/0f/15/332ca86cbebf25ddf98518caaf887945fbe1712b97a0f2493b\n",
      "Successfully built ConfigSpace autograd future smart-open sagemaker-mxnet-training retrying sagemaker-training inotify-simple boto3 contextvars kaggle openml liac-arff\n",
      "Installing collected packages: botocore, setuptools, s3transfer, pynacl, Pillow, murmurhash, future, cymem, catalogue, bcrypt, wasabi, typer, text-unidecode, srsly, smart-open, scikit-learn, pydantic, preshed, paramiko, graphviz, dill, ConfigSpace, boto3, blis, autograd, xmltodict, torch, thinc, spacy-legacy, retrying, regex, python-slugify, pyflakes, pycodestyle, portalocker, pathy, minio, mccabe, liac-arff, immutables, autogluon.core, zope.interface, zope.event, yacs, xxhash, torchvision, tokenizers, tensorboardx, spacy, sentencepiece, sacremoses, sacrebleu, plotly, openml, opencv-python, kaggle, greenlet, flake8, fastprogress, fastcore, decord, contextvars, autogluon.features, autocfg, xgboost, werkzeug, lightgbm, inotify-simple, gluoncv, gevent, fastai, d8, catboost, autogluon.tabular, autogluon.mxnet, autogluon-contrib-nlp, sagemaker-training, autogluon.vision, autogluon.text, autogluon.extra, sagemaker-mxnet-training, mxnet-cu110, autogluon\n",
      "  Attempting uninstall: botocore\n",
      "    Found existing installation: botocore 1.20.49\n",
      "    Uninstalling botocore-1.20.49:\n",
      "      Successfully uninstalled botocore-1.20.49\n",
      "  Attempting uninstall: setuptools\n",
      "    Found existing installation: setuptools 49.6.0.post20210108\n",
      "    Uninstalling setuptools-49.6.0.post20210108:\n",
      "      Successfully uninstalled setuptools-49.6.0.post20210108\n",
      "  Attempting uninstall: Pillow\n",
      "    Found existing installation: Pillow 8.1.2\n",
      "    Uninstalling Pillow-8.1.2:\n",
      "      Successfully uninstalled Pillow-8.1.2\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 0.23.1\n",
      "    Uninstalling scikit-learn-0.23.1:\n",
      "      Successfully uninstalled scikit-learn-0.23.1\n",
      "  Attempting uninstall: xgboost\n",
      "    Found existing installation: xgboost 1.4.0\n",
      "    Uninstalling xgboost-1.4.0:\n",
      "      Successfully uninstalled xgboost-1.4.0\n",
      "\u001b[91mWARNING: Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
      "distutils: /opt/conda/envs/rapids/include/python3.7m/UNKNOWN\n",
      "sysconfig: /opt/conda/envs/rapids/include/python3.7m\n",
      "\u001b[0m\u001b[91mWARNING: Additional context:\n",
      "user = False\n",
      "home = None\n",
      "root = None\n",
      "prefix = None\n",
      "\u001b[0m\u001b[91mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "dask-cudf 0.19.2 requires cupy-cuda102, which is not installed.\n",
      "cudf 0.19.2 requires cupy-cuda110, which is not installed.\n",
      "aiobotocore 1.3.0 requires botocore<1.20.50,>=1.20.49, but you have botocore 1.20.66 which is incompatible.\n",
      "\u001b[0mSuccessfully installed ConfigSpace-0.4.18 Pillow-8.1.0 autocfg-0.0.8 autogluon-0.2.0 autogluon-contrib-nlp-0.0.1b20210201 autogluon.core-0.2.0 autogluon.extra-0.2.0 autogluon.features-0.2.0 autogluon.mxnet-0.2.0 autogluon.tabular-0.2.0 autogluon.text-0.2.0 autogluon.vision-0.2.0 autograd-1.3 bcrypt-3.2.0 blis-0.7.4 boto3-1.17.66 botocore-1.20.66 catalogue-2.0.4 catboost-0.25.1 contextvars-2.4 cymem-2.0.5 d8-0.0.2.post0 decord-0.5.2 dill-0.3.3 fastai-2.3.1 fastcore-1.3.20 fastprogress-1.0.0 flake8-3.9.1 future-0.18.2 gevent-21.1.2 gluoncv-0.10.1.post0 graphviz-0.8.4 greenlet-1.0.0 immutables-0.15 inotify-simple-1.2.1 kaggle-1.5.12 liac-arff-2.5.0 lightgbm-3.2.1 mccabe-0.6.1 minio-7.0.3 murmurhash-1.0.5 mxnet-cu110-1.8.0.post0 opencv-python-4.5.1.48 openml-0.12.1 paramiko-2.7.2 pathy-0.5.2 plotly-4.14.3 portalocker-2.0.0 preshed-3.0.5 pycodestyle-2.7.0 pydantic-1.7.3 pyflakes-2.3.1 pynacl-1.4.0 python-slugify-5.0.0 regex-2021.4.4 retrying-1.3.3 s3transfer-0.4.2 sacrebleu-1.5.1 sacremoses-0.0.45 sagemaker-mxnet-training-4.3.0 sagemaker-training-3.9.2 scikit-learn-0.24.2 sentencepiece-0.1.95 setuptools-56.1.0 smart-open-3.0.0 spacy-3.0.6 spacy-legacy-3.0.5 srsly-2.4.1 tensorboardx-2.2 text-unidecode-1.3 thinc-8.0.3 tokenizers-0.9.4 torch-1.8.1 torchvision-0.9.1 typer-0.3.2 wasabi-0.8.2 werkzeug-1.0.1 xgboost-1.3.3 xmltodict-0.12.0 xxhash-2.0.2 yacs-0.1.8 zope.event-4.5.0 zope.interface-5.4.0\n",
      "\u001b[91mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\n",
      "\u001b[0mRemoving intermediate container f89436f20959\n",
      " ---> 0cc59ce8b985\n",
      "Step 12/13 : ENTRYPOINT []\n",
      " ---> Running in dabc5925d349\n",
      "Removing intermediate container dabc5925d349\n",
      " ---> cb9346f2baa3\n",
      "Step 13/13 : CMD [\"/bin/bash\"]\n",
      " ---> Running in 9cdc432cde1e\n",
      "Removing intermediate container 9cdc432cde1e\n",
      " ---> 213815a610e4\n",
      "Successfully built 213815a610e4\n",
      "Successfully tagged autogluon:latest\n",
      "The push refers to repository [152804913371.dkr.ecr.us-east-1.amazonaws.com/autogluon]\n",
      "\n",
      "\u001b[1B41dbe860: Preparing \n",
      "\u001b[1B260aa88a: Preparing \n",
      "\u001b[1B4de0a594: Preparing \n",
      "\u001b[1B03d339f6: Preparing \n",
      "\u001b[1B16f268c3: Preparing \n",
      "\u001b[1B51bd78ac: Preparing \n",
      "\u001b[1B01dbc7de: Preparing \n",
      "\u001b[1B31d2d72b: Preparing \n",
      "\u001b[1Ba966f459: Preparing \n",
      "\u001b[1Bb9e63cdf: Preparing \n",
      "\u001b[1B49f5bf51: Preparing \n",
      "\u001b[1Baa2fa9fe: Preparing \n",
      "\u001b[1B325cc380: Preparing \n",
      "\u001b[1Bdd81f9fa: Preparing \n",
      "\u001b[15B1dbe860: Pushed   3.742GB/3.712GB2A\u001b[2K\u001b[10A\u001b[2K\u001b[5A\u001b[2K\u001b[3A\u001b[2K\u001b[14A\u001b[2K\u001b[15A\u001b[2K\u001b[14A\u001b[2K\u001b[15A\u001b[2K\u001b[14A\u001b[2K\u001b[15A\u001b[2K\u001b[14A\u001b[2K\u001b[15A\u001b[2K\u001b[14A\u001b[2K\u001b[15A\u001b[2K\u001b[14A\u001b[2K\u001b[15A\u001b[2K\u001b[14A\u001b[2K\u001b[15A\u001b[2K\u001b[14A\u001b[2K\u001b[15A\u001b[2K\u001b[14A\u001b[2K\u001b[15A\u001b[2K\u001b[14A\u001b[2K\u001b[15A\u001b[2K\u001b[14A\u001b[2K\u001b[15A\u001b[2K\u001b[14A\u001b[2K\u001b[15A\u001b[2K\u001b[14A\u001b[2K\u001b[15A\u001b[2K\u001b[14A\u001b[2K\u001b[14A\u001b[2K\u001b[14A\u001b[2K\u001b[15A\u001b[2K\u001b[14A\u001b[2K\u001b[15A\u001b[2K\u001b[14A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[14A\u001b[2K\u001b[15A\u001b[2K\u001b[14A\u001b[2K\u001b[15A\u001b[2K\u001b[14A\u001b[2K\u001b[14A\u001b[2K\u001b[15A\u001b[2K\u001b[14A\u001b[2K\u001b[14A\u001b[2K\u001b[14A\u001b[2K\u001b[14A\u001b[2K\u001b[15A\u001b[2K\u001b[14A\u001b[2K\u001b[14A\u001b[2K\u001b[14A\u001b[2K\u001b[14A\u001b[2K\u001b[15A\u001b[2K\u001b[14A\u001b[2K\u001b[15A\u001b[2K\u001b[14A\u001b[2K\u001b[15A\u001b[2K\u001b[14A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[14A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2Klatest: digest: sha256:13faa9e293e812fb5164bfc0290a114a6e7265920f97b77516da3d97f769590b size: 3484\n"
     ]
    }
   ],
   "source": [
    "# build and push training image\n",
    "# !chmod u+x ./build_and_push.sh \n",
    "!./build_and_push.sh autogluon containers/training/Dockerfile.gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1887b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !./build_and_push.sh autogluon-small containers/training/Dockerfile_smaller.gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8273fa60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5e598aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_uri = \"152804913371.dkr.ecr.us-east-1.amazonaws.com/autogluon:latest\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36ded02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "27cbf38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoGluon(Framework):\n",
    "    def __init__(\n",
    "        self,\n",
    "        entry_point,\n",
    "        source_dir=None,\n",
    "        hyperparameters=None,\n",
    "        py_version=\"py3\",\n",
    "        framework_version=None,\n",
    "        image_uri=None,\n",
    "        distributions=None,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__(\n",
    "            entry_point, source_dir, hyperparameters, image_uri=image_uri, **kwargs\n",
    "        )\n",
    "    \n",
    "    def _configure_distribution(self, distributions):\n",
    "        return\n",
    "    \n",
    "    def create_model(\n",
    "        self,\n",
    "        model_server_workers=None,\n",
    "        role=None,\n",
    "        vpc_config_override=None,\n",
    "        entry_point=None,\n",
    "        source_dir=None,\n",
    "        dependencies=None,\n",
    "        image_name=None,\n",
    "        **kwargs\n",
    "    ):\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d89c95b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tabular_estimator =  AutoGluon(image_uri=image_uri,\n",
    "                      role=role,\n",
    "                      entry_point=\"training_scripts/tabular.py\",\n",
    "#                       source_dir='source_dir/',\n",
    "                      instance_count=1, \n",
    "                      #instance_type=\"local\", # we use local mode\n",
    "                      instance_type=\"ml.p3.2xlarge\",\n",
    "                      base_job_name=\"tabular-train\",\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "7c24a2c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-05 17:04:07 Starting - Starting the training job...\n",
      "2021-05-05 17:04:31 Starting - Launching requested ML instancesProfilerReport-1620234246: InProgress\n",
      "......\n",
      "2021-05-05 17:05:32 Starting - Preparing the instances for training.........\n",
      "2021-05-05 17:06:58 Downloading - Downloading input data\n",
      "2021-05-05 17:06:58 Training - Downloading the training image...............................\u001b[34m2021-05-05 17:12:12,077 sagemaker-training-toolkit INFO     Imported framework sagemaker_mxnet_container.training\u001b[0m\n",
      "\u001b[34m2021-05-05 17:12:12,100 sagemaker_mxnet_container.training INFO     MXNet training environment: {'SM_HOSTS': '[\"algo-1\"]', 'SM_NETWORK_INTERFACE_NAME': 'eth0', 'SM_HPS': '{}', 'SM_USER_ENTRY_POINT': 'tabular.py', 'SM_FRAMEWORK_PARAMS': '{}', 'SM_RESOURCE_CONFIG': '{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}', 'SM_INPUT_DATA_CONFIG': '{}', 'SM_OUTPUT_DATA_DIR': '/opt/ml/output/data', 'SM_CHANNELS': '[]', 'SM_CURRENT_HOST': 'algo-1', 'SM_MODULE_NAME': 'tabular', 'SM_LOG_LEVEL': '20', 'SM_FRAMEWORK_MODULE': 'sagemaker_mxnet_container.training:main', 'SM_INPUT_DIR': '/opt/ml/input', 'SM_INPUT_CONFIG_DIR': '/opt/ml/input/config', 'SM_OUTPUT_DIR': '/opt/ml/output', 'SM_NUM_CPUS': '8', 'SM_NUM_GPUS': '1', 'SM_MODEL_DIR': '/opt/ml/model', 'SM_MODULE_DIR': 's3://sagemaker-us-east-1-152804913371/tabular-train-2021-05-05-17-04-06-830/source/sourcedir.tar.gz', 'SM_TRAINING_ENV': '{\"additional_framework_parameters\":{},\"channel_input_dirs\":{},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_mxnet_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"tabular-train-2021-05-05-17-04-06-830\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-152804913371/tabular-train-2021-05-05-17-04-06-830/source/sourcedir.tar.gz\",\"module_name\":\"tabular\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"tabular.py\"}', 'SM_USER_ARGS': '[]', 'SM_OUTPUT_INTERMEDIATE_DIR': '/opt/ml/output/intermediate'}\u001b[0m\n",
      "\u001b[34m2021-05-05 17:12:15,597 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {},\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_mxnet_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {},\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {},\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"tabular-train-2021-05-05-17-04-06-830\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-152804913371/tabular-train-2021-05-05-17-04-06-830/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"tabular\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"tabular.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=tabular.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=tabular\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_mxnet_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=8\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-152804913371/tabular-train-2021-05-05-17-04-06-830/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_mxnet_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"tabular-train-2021-05-05-17-04-06-830\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-152804913371/tabular-train-2021-05-05-17-04-06-830/source/sourcedir.tar.gz\",\"module_name\":\"tabular\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"tabular.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/envs/rapids/bin:/opt/conda/envs/rapids/lib/python37.zip:/opt/conda/envs/rapids/lib/python3.7:/opt/conda/envs/rapids/lib/python3.7/lib-dynload:/opt/conda/envs/rapids/lib/python3.7/site-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/opt/conda/envs/rapids/bin/python3.7 tabular.py\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mWarning: path already exists! This predictor may overwrite an existing predictor! path=\"/opt/ml/model\"\u001b[0m\n",
      "\u001b[34mBeginning AutoGluon training ...\u001b[0m\n",
      "\u001b[34mAutoGluon will save models to \"/opt/ml/model/\"\u001b[0m\n",
      "\u001b[34mAutoGluon Version:  0.2.0\u001b[0m\n",
      "\u001b[34mTrain Data Rows:    500\u001b[0m\n",
      "\u001b[34mTrain Data Columns: 14\u001b[0m\n",
      "\u001b[34mPreprocessing data ...\u001b[0m\n",
      "\u001b[34mAutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\u001b[0m\n",
      "\u001b[34m#0112 unique label values:  [' >50K', ' <=50K']\u001b[0m\n",
      "\u001b[34m#011If 'binary' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\u001b[0m\n",
      "\u001b[34mSelected class <--> label mapping:  class 1 =  >50K, class 0 =  <=50K\u001b[0m\n",
      "\u001b[34m#011Note: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive ( >50K) vs negative ( <=50K) class.\u001b[0m\n",
      "\u001b[34m#011To explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\u001b[0m\n",
      "\u001b[34mUsing Feature Generators to preprocess the data ...\u001b[0m\n",
      "\u001b[34mFitting AutoMLPipelineFeatureGenerator...\u001b[0m\n",
      "\u001b[34m#011Available Memory:                    62288.93 MB\u001b[0m\n",
      "\u001b[34m#011Train Data (Original)  Memory Usage: 0.29 MB (0.0% of available memory)\u001b[0m\n",
      "\u001b[34m#011Inferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\u001b[0m\n",
      "\u001b[34m#011Stage 1 Generators:\u001b[0m\n",
      "\u001b[34m#011#011Fitting AsTypeFeatureGenerator...\u001b[0m\n",
      "\u001b[34m#011Stage 2 Generators:\u001b[0m\n",
      "\u001b[34m#011#011Fitting FillNaFeatureGenerator...\u001b[0m\n",
      "\u001b[34m#011Stage 3 Generators:\u001b[0m\n",
      "\u001b[34m#011#011Fitting IdentityFeatureGenerator...\u001b[0m\n",
      "\u001b[34m#011#011Fitting CategoryFeatureGenerator...\u001b[0m\n",
      "\u001b[34m#011#011#011Fitting CategoryMemoryMinimizeFeatureGenerator...\u001b[0m\n",
      "\u001b[34m#011Stage 4 Generators:\u001b[0m\n",
      "\u001b[34m#011#011Fitting DropUniqueFeatureGenerator...\u001b[0m\n",
      "\u001b[34m#011Types of features in original data (raw dtype, special dtypes):\u001b[0m\n",
      "\u001b[34m#011#011('int', [])    : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\u001b[0m\n",
      "\u001b[34m#011#011('object', []) : 8 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\u001b[0m\n",
      "\u001b[34m#011Types of features in processed data (raw dtype, special dtypes):\u001b[0m\n",
      "\u001b[34m#011#011('category', []) : 8 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\u001b[0m\n",
      "\u001b[34m#011#011('int', [])      : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\u001b[0m\n",
      "\u001b[34m#0110.1s = Fit runtime\u001b[0m\n",
      "\u001b[34m#01114 features in original data used to generate 14 features in processed data.\u001b[0m\n",
      "\u001b[34m#011Train Data (Processed) Memory Usage: 0.03 MB (0.0% of available memory)\u001b[0m\n",
      "\u001b[34mData preprocessing and feature engineering runtime = 0.09s ...\u001b[0m\n",
      "\u001b[34mAutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\u001b[0m\n",
      "\u001b[34m#011To change this, specify the eval_metric argument of fit()\u001b[0m\n",
      "\u001b[34mAutomatically generating train/validation split with holdout_frac=0.2, Train Rows: 400, Val Rows: 100\u001b[0m\n",
      "\u001b[34mFitting model: KNeighborsUnif ...\u001b[0m\n",
      "\u001b[34m#0110.73#011 = Validation accuracy score\u001b[0m\n",
      "\u001b[34m#0110.0s#011 = Training runtime\u001b[0m\n",
      "\u001b[34m#0110.11s#011 = Validation runtime\u001b[0m\n",
      "\u001b[34mFitting model: KNeighborsDist ...\u001b[0m\n",
      "\u001b[34m#0110.65#011 = Validation accuracy score\u001b[0m\n",
      "\u001b[34m#0110.0s#011 = Training runtime\u001b[0m\n",
      "\u001b[34m#0110.1s#011 = Validation runtime\u001b[0m\n",
      "\u001b[34mFitting model: LightGBMXT ...\u001b[0m\n",
      "\u001b[34m/opt/conda/envs/rapids/lib/python3.7/site-packages/fsspec/__init__.py:47: DeprecationWarning: SelectableGroups dict interface is deprecated. Use select.\n",
      "  for spec in entry_points.get(\"fsspec.specs\", []):\u001b[0m\n",
      "\u001b[34m#0110.83#011 = Validation accuracy score\u001b[0m\n",
      "\u001b[34m#0112.15s#011 = Training runtime\u001b[0m\n",
      "\u001b[34m#0110.01s#011 = Validation runtime\u001b[0m\n",
      "\u001b[34mFitting model: LightGBM ...\u001b[0m\n",
      "\u001b[34m#0110.85#011 = Validation accuracy score\u001b[0m\n",
      "\u001b[34m#0110.23s#011 = Training runtime\u001b[0m\n",
      "\u001b[34m#0110.01s#011 = Validation runtime\u001b[0m\n",
      "\u001b[34mFitting model: RandomForestGini ...\u001b[0m\n",
      "\u001b[34m#0110.84#011 = Validation accuracy score\u001b[0m\n",
      "\u001b[34m#0110.89s#011 = Training runtime\u001b[0m\n",
      "\u001b[34m#0110.11s#011 = Validation runtime\u001b[0m\n",
      "\u001b[34mFitting model: RandomForestEntr ...\u001b[0m\n",
      "\u001b[34m#0110.83#011 = Validation accuracy score\u001b[0m\n",
      "\u001b[34m#0110.84s#011 = Training runtime\u001b[0m\n",
      "\u001b[34m#0110.11s#011 = Validation runtime\u001b[0m\n",
      "\u001b[34mFitting model: CatBoost ...\u001b[0m\n",
      "\n",
      "2021-05-05 17:12:34 Training - Training image download completed. Training in progress.\u001b[34m#0110.84#011 = Validation accuracy score\u001b[0m\n",
      "\u001b[34m#0110.7s#011 = Training runtime\u001b[0m\n",
      "\u001b[34m#0110.01s#011 = Validation runtime\u001b[0m\n",
      "\u001b[34mFitting model: ExtraTreesGini ...\u001b[0m\n",
      "\u001b[34m#0110.82#011 = Validation accuracy score\u001b[0m\n",
      "\u001b[34m#0110.85s#011 = Training runtime\u001b[0m\n",
      "\u001b[34m#0110.11s#011 = Validation runtime\u001b[0m\n",
      "\u001b[34mFitting model: ExtraTreesEntr ...\u001b[0m\n",
      "\u001b[34m#0110.82#011 = Validation accuracy score\u001b[0m\n",
      "\u001b[34m#0110.85s#011 = Training runtime\u001b[0m\n",
      "\u001b[34m#0110.11s#011 = Validation runtime\u001b[0m\n",
      "\u001b[34mFitting model: NeuralNetFastAI ...\u001b[0m\n",
      "\u001b[34mgenerated new fontManager\u001b[0m\n",
      "\u001b[34m#0110.83#011 = Validation accuracy score\u001b[0m\n",
      "\u001b[34m#01110.14s#011 = Training runtime\u001b[0m\n",
      "\u001b[34m#0110.04s#011 = Validation runtime\u001b[0m\n",
      "\u001b[34mFitting model: XGBoost ...\u001b[0m\n",
      "\u001b[34m#0110.85#011 = Validation accuracy score\u001b[0m\n",
      "\u001b[34m#0111.85s#011 = Training runtime\u001b[0m\n",
      "\u001b[34m#0110.01s#011 = Validation runtime\u001b[0m\n",
      "\u001b[34mFitting model: NeuralNetMXNet ...\u001b[0m\n",
      "\u001b[34m[17:12:43] ../src/base.cc:80: cuDNN lib mismatch: linked-against version 8100 != compiled-against version 8004.  Set MXNET_CUDNN_LIB_CHECKING=0 to quiet this warning.\u001b[0m\n",
      "\u001b[34m#0110.84#011 = Validation accuracy score\u001b[0m\n",
      "\u001b[34m#0118.21s#011 = Training runtime\u001b[0m\n",
      "\u001b[34m#0110.14s#011 = Validation runtime\u001b[0m\n",
      "\u001b[34mFitting model: LightGBMLarge ...\u001b[0m\n",
      "\u001b[34m#0110.83#011 = Validation accuracy score\u001b[0m\n",
      "\u001b[34m#0110.56s#011 = Training runtime\u001b[0m\n",
      "\u001b[34m#0110.02s#011 = Validation runtime\u001b[0m\n",
      "\u001b[34mFitting model: WeightedEnsemble_L2 ...\u001b[0m\n",
      "\u001b[34m#0110.85#011 = Validation accuracy score\u001b[0m\n",
      "\u001b[34m#0110.52s#011 = Training runtime\u001b[0m\n",
      "\u001b[34m#0110.0s#011 = Validation runtime\u001b[0m\n",
      "\u001b[34mAutoGluon training complete, total runtime = 29.92s ...\u001b[0m\n",
      "\u001b[34mTabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/opt/ml/model/\")\u001b[0m\n",
      "\u001b[34m2021-05-05 17:12:51,930 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2021-05-05 17:13:00 Uploading - Uploading generated training model\n",
      "2021-05-05 17:13:00 Completed - Training job completed\n",
      "Training seconds: 369\n",
      "Billable seconds: 369\n"
     ]
    }
   ],
   "source": [
    "tabular_estimator.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "68765c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.inputs import TrainingInput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6d77d3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "key_prefix=\"otto_group\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d4611858",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input = TrainingInput(f\"s3://{bucket}/{key_prefix}/train.csv\", content_type=\"text/csv\")\n",
    "validation_input = TrainingInput(f\"s3://{bucket}/{key_prefix}/test.csv\", content_type=\"text/csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5fa7dc16",
   "metadata": {},
   "outputs": [],
   "source": [
    "rapids_estimator =  AutoGluon(image_uri=image_uri,\n",
    "                      role=role,\n",
    "                      entry_point=\"training_scripts/rapids.py\",\n",
    "#                       source_dir='source_dir/',\n",
    "                      instance_count=1, \n",
    "                      #instance_type=\"local\", # we use local mode\n",
    "                      instance_type=\"ml.p3.2xlarge\",\n",
    "                      base_job_name=\"rapids-train\",\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f9d70682",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-05 14:54:11 Starting - Starting the training job...\n",
      "2021-05-05 14:54:36 Starting - Launching requested ML instancesProfilerReport-1620226451: InProgress\n",
      "......\n",
      "2021-05-05 14:55:36 Starting - Preparing the instances for training.........\n",
      "2021-05-05 14:57:01 Downloading - Downloading input data\n",
      "2021-05-05 14:57:01 Training - Downloading the training image..............................\n",
      "2021-05-05 15:02:12 Training - Training image download completed. Training in progress..\u001b[34m2021-05-05 15:02:13,076 sagemaker-training-toolkit INFO     Imported framework sagemaker_mxnet_container.training\u001b[0m\n",
      "\u001b[34m2021-05-05 15:02:13,099 sagemaker_mxnet_container.training INFO     MXNet training environment: {'SM_HOSTS': '[\"algo-1\"]', 'SM_NETWORK_INTERFACE_NAME': 'eth0', 'SM_HPS': '{}', 'SM_USER_ENTRY_POINT': 'rapids.py', 'SM_FRAMEWORK_PARAMS': '{}', 'SM_RESOURCE_CONFIG': '{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}', 'SM_INPUT_DATA_CONFIG': '{\"test\":{\"ContentType\":\"text/csv\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"ContentType\":\"text/csv\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}', 'SM_OUTPUT_DATA_DIR': '/opt/ml/output/data', 'SM_CHANNELS': '[\"test\",\"train\"]', 'SM_CURRENT_HOST': 'algo-1', 'SM_MODULE_NAME': 'rapids', 'SM_LOG_LEVEL': '20', 'SM_FRAMEWORK_MODULE': 'sagemaker_mxnet_container.training:main', 'SM_INPUT_DIR': '/opt/ml/input', 'SM_INPUT_CONFIG_DIR': '/opt/ml/input/config', 'SM_OUTPUT_DIR': '/opt/ml/output', 'SM_NUM_CPUS': '8', 'SM_NUM_GPUS': '1', 'SM_MODEL_DIR': '/opt/ml/model', 'SM_MODULE_DIR': 's3://sagemaker-us-east-1-152804913371/rapids-train-2021-05-05-14-54-11-472/source/sourcedir.tar.gz', 'SM_TRAINING_ENV': '{\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_mxnet_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"test\":{\"ContentType\":\"text/csv\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"ContentType\":\"text/csv\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"rapids-train-2021-05-05-14-54-11-472\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-152804913371/rapids-train-2021-05-05-14-54-11-472/source/sourcedir.tar.gz\",\"module_name\":\"rapids\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"rapids.py\"}', 'SM_USER_ARGS': '[]', 'SM_OUTPUT_INTERMEDIATE_DIR': '/opt/ml/output/intermediate', 'SM_CHANNEL_TEST': '/opt/ml/input/data/test', 'SM_CHANNEL_TRAIN': '/opt/ml/input/data/train'}\u001b[0m\n",
      "\u001b[34m2021-05-05 15:02:13,900 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"test\": \"/opt/ml/input/data/test\",\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_mxnet_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {},\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"test\": {\n",
      "            \"ContentType\": \"text/csv\",\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"ContentType\": \"text/csv\",\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"rapids-train-2021-05-05-14-54-11-472\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-152804913371/rapids-train-2021-05-05-14-54-11-472/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"rapids\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"rapids.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=rapids.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"test\":{\"ContentType\":\"text/csv\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"ContentType\":\"text/csv\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"test\",\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=rapids\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_mxnet_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=8\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-152804913371/rapids-train-2021-05-05-14-54-11-472/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_mxnet_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"test\":{\"ContentType\":\"text/csv\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"ContentType\":\"text/csv\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"rapids-train-2021-05-05-14-54-11-472\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-152804913371/rapids-train-2021-05-05-14-54-11-472/source/sourcedir.tar.gz\",\"module_name\":\"rapids\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"rapids.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TEST=/opt/ml/input/data/test\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/envs/rapids/bin:/opt/conda/envs/rapids/lib/python37.zip:/opt/conda/envs/rapids/lib/python3.7:/opt/conda/envs/rapids/lib/python3.7/lib-dynload:/opt/conda/envs/rapids/lib/python3.7/site-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/opt/conda/envs/rapids/bin/python3.7 rapids.py\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mWarning: path already exists! This predictor may overwrite an existing predictor! path=\"/opt/ml/model\"\u001b[0m\n",
      "\u001b[34mPresets specified: ['best_quality']\u001b[0m\n",
      "\u001b[34mBeginning AutoGluon training ...\u001b[0m\n",
      "\u001b[34mAutoGluon will save models to \"/opt/ml/model/\"\u001b[0m\n",
      "\u001b[34mAutoGluon Version:  0.2.0\u001b[0m\n",
      "\u001b[34mTrain Data Rows:    61878\u001b[0m\n",
      "\u001b[34mTrain Data Columns: 94\u001b[0m\n",
      "\u001b[34mPreprocessing data ...\u001b[0m\n",
      "\u001b[34mAutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == object).\u001b[0m\n",
      "\u001b[34m#0119 unique label values:  ['Class_1', 'Class_2', 'Class_3', 'Class_4', 'Class_5', 'Class_6', 'Class_7', 'Class_8', 'Class_9']\u001b[0m\n",
      "\u001b[34m#011If 'multiclass' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\u001b[0m\n",
      "\u001b[34mTrain Data Class Count: 9\u001b[0m\n",
      "\u001b[34mUsing Feature Generators to preprocess the data ...\u001b[0m\n",
      "\u001b[34mDropping user-specified ignored columns: ['id']\u001b[0m\n",
      "\u001b[34mFitting AutoMLPipelineFeatureGenerator...\u001b[0m\n",
      "\u001b[34m#011Available Memory:                    61991.16 MB\u001b[0m\n",
      "\u001b[34m#011Train Data (Original)  Memory Usage: 46.04 MB (0.1% of available memory)\u001b[0m\n",
      "\u001b[34m#011Inferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\u001b[0m\n",
      "\u001b[34m#011Stage 1 Generators:\u001b[0m\n",
      "\u001b[34m#011#011Fitting AsTypeFeatureGenerator...\u001b[0m\n",
      "\u001b[34m#011Stage 2 Generators:\u001b[0m\n",
      "\u001b[34m#011#011Fitting FillNaFeatureGenerator...\u001b[0m\n",
      "\u001b[34m#011Stage 3 Generators:\u001b[0m\n",
      "\u001b[34m#011#011Fitting IdentityFeatureGenerator...\u001b[0m\n",
      "\u001b[34m#011Stage 4 Generators:\u001b[0m\n",
      "\u001b[34m#011#011Fitting DropUniqueFeatureGenerator...\u001b[0m\n",
      "\u001b[34m#011Types of features in original data (raw dtype, special dtypes):\u001b[0m\n",
      "\u001b[34m#011#011('int', []) : 93 | ['feat_1', 'feat_2', 'feat_3', 'feat_4', 'feat_5', ...]\u001b[0m\n",
      "\u001b[34m#011Types of features in processed data (raw dtype, special dtypes):\u001b[0m\n",
      "\u001b[34m#011#011('int', []) : 93 | ['feat_1', 'feat_2', 'feat_3', 'feat_4', 'feat_5', ...]\u001b[0m\n",
      "\u001b[34m#0110.4s = Fit runtime\u001b[0m\n",
      "\u001b[34m#01193 features in original data used to generate 93 features in processed data.\u001b[0m\n",
      "\u001b[34m#011Train Data (Processed) Memory Usage: 46.04 MB (0.1% of available memory)\u001b[0m\n",
      "\u001b[34mData preprocessing and feature engineering runtime = 0.62s ...\u001b[0m\n",
      "\u001b[34mAutoGluon will gauge predictive performance using evaluation metric: 'log_loss'\u001b[0m\n",
      "\u001b[34m#011This metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\u001b[0m\n",
      "\u001b[34m#011To change this, specify the eval_metric argument of fit()\u001b[0m\n",
      "\u001b[34mCustom Model Type Detected: <class 'autogluon.tabular.models.knn.knn_rapids_model.KNNRapidsModel'>\u001b[0m\n",
      "\u001b[34mCustom Model Type Detected: <class 'autogluon.tabular.models.lr.lr_rapids_model.LinearRapidsModel'>\u001b[0m\n",
      "\u001b[34mFitting model: RandomForest_BAG_L1 ...\u001b[0m\n",
      "\u001b[34m#011-0.568#011 = Validation log_loss score\u001b[0m\n",
      "\u001b[34m#0118.98s#011 = Training runtime\u001b[0m\n",
      "\u001b[34m#0115.06s#011 = Validation runtime\u001b[0m\n",
      "\u001b[34mFitting model: CatBoost_BAG_L1 ...\u001b[0m\n",
      "\u001b[34m#011Training S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\u001b[0m\n",
      "\u001b[34m#011Training S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\u001b[0m\n",
      "\u001b[34m#011Training S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\u001b[0m\n",
      "\u001b[34m#011Training S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\u001b[0m\n",
      "\u001b[34m#011Training S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\u001b[0m\n",
      "\u001b[34m#011Training S1F6 with GPU, note that this may negatively impact model quality compared to CPU training.\u001b[0m\n",
      "\u001b[34m#011Training S1F7 with GPU, note that this may negatively impact model quality compared to CPU training.\u001b[0m\n",
      "\u001b[34m#011Training S1F8 with GPU, note that this may negatively impact model quality compared to CPU training.\u001b[0m\n",
      "\u001b[34m#011Training S1F9 with GPU, note that this may negatively impact model quality compared to CPU training.\u001b[0m\n",
      "\u001b[34m#011Training S1F10 with GPU, note that this may negatively impact model quality compared to CPU training.\u001b[0m\n",
      "\u001b[34m#011-0.4666#011 = Validation log_loss score\u001b[0m\n",
      "\u001b[34m#011288.57s#011 = Training runtime\u001b[0m\n",
      "\u001b[34m#0110.74s#011 = Validation runtime\u001b[0m\n",
      "\u001b[34mFitting model: XGBoost_BAG_L1 ...\u001b[0m\n",
      "\u001b[34m/opt/conda/envs/rapids/lib/python3.7/site-packages/fsspec/__init__.py:47: DeprecationWarning: SelectableGroups dict interface is deprecated. Use select.\n",
      "  for spec in entry_points.get(\"fsspec.specs\", []):\u001b[0m\n",
      "\u001b[34m#011-0.4718#011 = Validation log_loss score\u001b[0m\n",
      "\u001b[34m#011210.35s#011 = Training runtime\u001b[0m\n",
      "\u001b[34m#0112.93s#011 = Validation runtime\u001b[0m\n",
      "\u001b[34mFitting model: KNNRapidsModel_BAG_L1 ...\u001b[0m\n",
      "\u001b[34m/opt/conda/envs/rapids/lib/python3.7/site-packages/cuml/preprocessing/model_selection.py:25: DeprecationWarning: cuml.preprocessing.model_selection is deprecated and will be removed in v0.18. Use cuml.model_selection instead.\n",
      "  DeprecationWarning)\u001b[0m\n",
      "\u001b[34m/opt/conda/envs/rapids/lib/python3.7/site-packages/cupy/sparse/__init__.py:17: DeprecationWarning: cupy.sparse is deprecated. Use cupyx.scipy.sparse instead.\n",
      "  warnings.warn(msg, DeprecationWarning)\u001b[0m\n",
      "\u001b[34minit\u001b[0m\n",
      "\u001b[34m#011-1.269#011 = Validation log_loss score\u001b[0m\n",
      "\u001b[34m#0115.97s#011 = Training runtime\u001b[0m\n",
      "\u001b[34m#0113.06s#011 = Validation runtime\u001b[0m\n",
      "\u001b[34mFitting model: LinearRapidsModel_BAG_L1 ...\u001b[0m\n",
      "\u001b[34m#011-0.7539#011 = Validation log_loss score\u001b[0m\n",
      "\u001b[34m#01159.75s#011 = Training runtime\u001b[0m\n",
      "\u001b[34m#0114.64s#011 = Validation runtime\u001b[0m\n",
      "\u001b[34mFitting model: WeightedEnsemble_L2 ...\u001b[0m\n",
      "\u001b[34m#011-0.4488#011 = Validation log_loss score\u001b[0m\n",
      "\u001b[34m#01119.12s#011 = Training runtime\u001b[0m\n",
      "\u001b[34m#0110.02s#011 = Validation runtime\u001b[0m\n",
      "\u001b[34mCustom Model Type Detected: <class 'autogluon.tabular.models.knn.knn_rapids_model.KNNRapidsModel'>\u001b[0m\n",
      "\u001b[34mCustom Model Type Detected: <class 'autogluon.tabular.models.lr.lr_rapids_model.LinearRapidsModel'>\u001b[0m\n",
      "\u001b[34mFitting model: RandomForest_BAG_L2 ...\u001b[0m\n",
      "\u001b[34m#011-0.4762#011 = Validation log_loss score\u001b[0m\n",
      "\u001b[34m#01118.27s#011 = Training runtime\u001b[0m\n",
      "\u001b[34m#0115.78s#011 = Validation runtime\u001b[0m\n",
      "\u001b[34mFitting model: CatBoost_BAG_L2 ...\u001b[0m\n",
      "\u001b[34m#011Training S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\u001b[0m\n",
      "\u001b[34m#011Training S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\u001b[0m\n",
      "\u001b[34m#011Training S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\u001b[0m\n",
      "\u001b[34m#011Training S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\u001b[0m\n",
      "\u001b[34m#011Training S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\u001b[0m\n",
      "\u001b[34m#011Training S1F6 with GPU, note that this may negatively impact model quality compared to CPU training.\u001b[0m\n",
      "\u001b[34m#011Training S1F7 with GPU, note that this may negatively impact model quality compared to CPU training.\u001b[0m\n",
      "\u001b[34m#011Training S1F8 with GPU, note that this may negatively impact model quality compared to CPU training.\u001b[0m\n",
      "\u001b[34m#011Training S1F9 with GPU, note that this may negatively impact model quality compared to CPU training.\u001b[0m\n",
      "\u001b[34m#011Training S1F10 with GPU, note that this may negatively impact model quality compared to CPU training.\u001b[0m\n",
      "\u001b[34m#011-0.4314#011 = Validation log_loss score\u001b[0m\n",
      "\u001b[34m#01168.16s#011 = Training runtime\u001b[0m\n",
      "\u001b[34m#0110.32s#011 = Validation runtime\u001b[0m\n",
      "\u001b[34mFitting model: XGBoost_BAG_L2 ...\u001b[0m\n",
      "\u001b[34m#011-0.4305#011 = Validation log_loss score\u001b[0m\n",
      "\u001b[34m#01169.15s#011 = Training runtime\u001b[0m\n",
      "\u001b[34m#0111.88s#011 = Validation runtime\u001b[0m\n",
      "\u001b[34mFitting model: KNNRapidsModel_BAG_L2 ...\u001b[0m\n",
      "\u001b[34m#011-1.2403#011 = Validation log_loss score\u001b[0m\n",
      "\u001b[34m#0110.77s#011 = Training runtime\u001b[0m\n",
      "\u001b[34m#0111.79s#011 = Validation runtime\u001b[0m\n",
      "\u001b[34mFitting model: LinearRapidsModel_BAG_L2 ...\u001b[0m\n",
      "\u001b[34m#011-0.446#011 = Validation log_loss score\u001b[0m\n",
      "\u001b[34m#01171.89s#011 = Training runtime\u001b[0m\n",
      "\u001b[34m#0114.28s#011 = Validation runtime\u001b[0m\n",
      "\u001b[34mFitting model: WeightedEnsemble_L3 ...\u001b[0m\n",
      "\u001b[34m#011-0.4248#011 = Validation log_loss score\u001b[0m\n",
      "\u001b[34m#01118.88s#011 = Training runtime\u001b[0m\n",
      "\u001b[34m#0110.01s#011 = Validation runtime\u001b[0m\n",
      "\u001b[34mAutoGluon training complete, total runtime = 883.74s ...\u001b[0m\n",
      "\u001b[34mTabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/opt/ml/model/\")\u001b[0m\n",
      "\u001b[34m2021-05-05 15:17:05,804 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2021-05-05 15:17:22 Uploading - Uploading generated training model\n",
      "2021-05-05 15:20:51 Completed - Training job completed\n",
      "Training seconds: 1438\n",
      "Billable seconds: 1438\n"
     ]
    }
   ],
   "source": [
    "rapids_estimator.fit({'train': train_input, 'test': validation_input}, \n",
    "              wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8f3b09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
